model_direct: /home/codee/scratch/sourcecode/cem-dataset/evaluation/savemodel
load the pretrain state with cellemnet_mocov2
Using model with 32515703 trainable parameters!
Found 49 images in /home/codee/scratch/sourcecode/cem-dataset/benchdata/guay/2d/train/images
Found 23 images in /home/codee/scratch/sourcecode/cem-dataset/benchdata/guay/2d/valid/images
  1%|          | 1/100 [00:00<?, ?it/s]epochnum: 1
torch.Size([16, 1, 512, 512])
outputshape: torch.Size([16, 7, 512, 512])
loss: 2.1688404083251953
  2%|▏         | 2/100 [00:22<36:11, 22.16s/it]epochnum: 2
torch.Size([16, 1, 512, 512])
outputshape: torch.Size([16, 7, 512, 512])
loss: 1.9770457744598389
  3%|▎         | 3/100 [00:34<26:45, 16.55s/it]epochnum: 3
torch.Size([16, 1, 512, 512])
outputshape: torch.Size([16, 7, 512, 512])
loss: 1.8730252981185913
  4%|▍         | 4/100 [00:47<23:28, 14.67s/it]epochnum: 4
torch.Size([16, 1, 512, 512])
outputshape: torch.Size([16, 7, 512, 512])
loss: 1.699381947517395
  5%|▌         | 5/100 [01:01<22:58, 14.51s/it]epochnum: 5
torch.Size([16, 1, 512, 512])
outputshape: torch.Size([16, 7, 512, 512])
loss: 1.5178730487823486


train_loss: 1.841
items: dict_items([('IoU', <resources.metrics.IoU object at 0x2ab37d4158d0>)])
back_IoU: 0.177
cell_IoU: 0.125
mito_IoU: 0.007
can_chan_IoU: 0.079
alpha_gran_IoU: 0.032
dense_gran_IoU: 0.003
dense_gran_core_IoU: 0.001


valid_loss: 1.782
items: dict_items([('IoU', <resources.metrics.IoU object at 0x2ab37e51c850>)])
back_IoU: 0.182
cell_IoU: 0.127
mito_IoU: 0.015
can_chan_IoU: 0.030
alpha_gran_IoU: 0.022
dense_gran_IoU: 0.001
dense_gran_core_IoU: 0.000
  6%|▌         | 6/100 [01:27<29:14, 18.67s/it]epochnum: 6
torch.Size([16, 1, 512, 512])
outputshape: torch.Size([16, 7, 512, 512])
loss: 1.4275522232055664
  7%|▋         | 7/100 [01:39<25:14, 16.28s/it]epochnum: 7
torch.Size([16, 1, 512, 512])
outputshape: torch.Size([16, 7, 512, 512])
loss: 1.2813161611557007
  8%|▊         | 8/100 [01:53<23:54, 15.60s/it]epochnum: 8
torch.Size([16, 1, 512, 512])
outputshape: torch.Size([16, 7, 512, 512])
loss: 1.1672589778900146
  9%|▉         | 9/100 [02:04<21:39, 14.28s/it]epochnum: 9
torch.Size([16, 1, 512, 512])
outputshape: torch.Size([16, 7, 512, 512])
loss: 1.1232452392578125
 10%|█         | 10/100 [02:15<19:38, 13.10s/it]epochnum: 10
torch.Size([16, 1, 512, 512])
outputshape: torch.Size([16, 7, 512, 512])
loss: 1.1204999685287476


train_loss: 1.221
items: dict_items([('IoU', <resources.metrics.IoU object at 0x2ab37d4158d0>)])
back_IoU: 0.334
cell_IoU: 0.228
mito_IoU: 0.007
can_chan_IoU: 0.174
alpha_gran_IoU: 0.040
dense_gran_IoU: 0.005
dense_gran_core_IoU: 0.001


valid_loss: 1.151
items: dict_items([('IoU', <resources.metrics.IoU object at 0x2ab37e51c850>)])
back_IoU: 0.575
cell_IoU: 0.192
mito_IoU: 0.023
can_chan_IoU: 0.101
alpha_gran_IoU: 0.037
dense_gran_IoU: 0.004
dense_gran_core_IoU: 0.000
 11%|█         | 11/100 [02:44<26:39, 17.98s/it]epochnum: 11
torch.Size([16, 1, 512, 512])
outputshape: torch.Size([16, 7, 512, 512])
loss: 0.9783576130867004
 12%|█▏        | 12/100 [02:55<23:33, 16.06s/it]